@article{goda2019multilevel,
  title={Multilevel Monte Carlo estimation of log marginal likelihood},
  author={Goda, Takashi and Ishikawa, Kei},
  journal={arXiv preprint arXiv:1912.10636},
  year={2019}
}

@inproceedings{ishikawa2021efficient,
  title = {Efficient Debiased Evidence Estimation by Multilevel Monte Carlo Sampling},
  author = {Ishikawa,Kei and Goda,Takashi},
  booktitle = {Uncertainty in Artificial Intelligence},
  pages = {34--43},
  year = {2021},
  organization = {PMLR},
  abstract = {In this paper, we propose a new stochastic optimization algorithm for Bayesian inference based on multilevel Monte Carlo (MLMC) methods. In Bayesian statistics, biased estimators of the model evidence have been often used as stochastic objectives because the existing debiasing techniques are computationally costly to apply. To overcome this issue, we apply an MLMC sampling technique to construct low-variance unbiased estimators both for the model evidence and its gradient. In the theoretical analysis, we show that the computational cost required for our proposed MLMC estimator to estimate the model evidence or its gradient with a given accuracy is an order of magnitude smaller than those of the previously known estimators. Our numerical experiments confirm considerable computational savings compared to the conventional estimators. Combining our MLMC estimator with gradient-based stochastic optimization results in a new scalable, efficient, debiased inference algorithm for Bayesian statistical models.},
  archiveprefix = {arXiv},
  primaryclass = {stat.ML},
  arxiv = {2001.04676},
  bibtex_show = {true},
  selected = {true},
}

@inproceedings{ishikawa2023kernel,
  title = {Kernel Conditional Moment Constraints for Confounding Robust Inference},
  author = {Ishikawa, Kei and He, Niao},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  pages = {650--674},
  year = {2023},
  organization = {PMLR},
  abstract = {We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value. It can be shown that our estimator contains the recently proposed sharp estimator by Dorn and Guo (2022) as a special case, and our method enables a novel extension of the classical marginal sensitivity model using f-divergence. To construct our estimator, we leverage the kernel method to obtain a tractable approximation to the conditional moment constraints, which traditional non-sharp estimators failed to take into account. In the theoretical analysis, we provide a condition for the choice of the kernel which guarantees no specification error that biases the lower bound estimation. Furthermore, we provide consistency guarantees of policy evaluation and learning. In the experiments with synthetic and real-world data, we demonstrate the effectiveness of the proposed method.},
  archiveprefix = {arXiv},
  primaryclass = {stat.ML},
  arxiv = {2302.13348},
  bibtex_show = {true},
  selected = {true},
}

@article{ishikawa2023convex,
  title={A Convex Framework for Confounding Robust Inference},
  author={Ishikawa, Kei and He, Naio and Kanamori, Takafumi},
  journal={arXiv preprint arXiv:2309.12450},
  year={2023}
  abstract = {We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value using convex programming. The generality of our estimator enables various extensions such as sensitivity analysis with f-divergence, model selection with cross validation and information criterion, and robust policy learning with the sharp lower bound. Furthermore, our estimation method can be reformulated as an empirical risk minimization problem thanks to the strong duality, which enables us to provide strong theoretical guarantees of the proposed estimator using techniques of the M-estimation.},
  archiveprefix = {arXiv},
  primaryclass = {stat.ML},
  arxiv = {2309.12450},
  bibtex_show = {true},
  selected = {false},
}

@article{ishikawa2023dmlmc,
  title={On the Parallel Complexity of Multilevel Monte Carlo in Stocahstic Gradient Descent},
  author={Ishikawa, Kei},
  journal={arXiv preprint arXiv:2310.02402},
  year={2023}
  abstract = {In the stochastic gradient descent (SGD) for sequential simulations such as the neural stochastic differential equations, the Multilevel Monte Carlo (MLMC) method is known to offer better theoretical computational complexity compared to the naive Monte Carlo approach. However, in practice, MLMC scales poorly on massively parallel computing platforms such as modern GPUs, because of its large parallel complexity which is equivalent to that of the naive Monte Carlo method. To cope with this issue, we propose the delayed MLMC gradient estimator that drastically reduces the parallel complexity of MLMC by recycling previously computed gradient components from earlier steps of SGD. The proposed estimator provably reduces the average parallel complexity per iteration at the cost of a slightly worse per-iteration convergence rate. In our numerical experiments, we use an example of deep hedging to demonstrate the superior parallel complexity of our method compared to the standard MLMC in SGD.},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG},
  arxiv = {2310.02402},
  bibtex_show = {true},
  selected = {false},
}
